{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow is NOT using the GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in command prompt base:\n",
    "/mnt/c/Users/Ryan/Desktop/scouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/ryan/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/ryan/.local/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ryan/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"nlp\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:13:31.767647: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2024-01-08 14:13:31.852478: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 456s 14ms/step - loss: 1.6214\n",
      "Epoch 2/10\n",
      "31368/31368 [==============================] - 450s 14ms/step - loss: 1.5404\n",
      "Epoch 3/10\n",
      "31368/31368 [==============================] - 448s 14ms/step - loss: 1.5192\n",
      "Epoch 4/10\n",
      "31368/31368 [==============================] - 460s 15ms/step - loss: 1.5076\n",
      "Epoch 5/10\n",
      "31368/31368 [==============================] - 453s 14ms/step - loss: 1.4999\n",
      "Epoch 6/10\n",
      "31368/31368 [==============================] - 447s 14ms/step - loss: 1.4946\n",
      "Epoch 7/10\n",
      "31368/31368 [==============================] - 452s 14ms/step - loss: 1.4910\n",
      "Epoch 8/10\n",
      "31368/31368 [==============================] - 462s 15ms/step - loss: 1.4882\n",
      "Epoch 9/10\n",
      "31368/31368 [==============================] - 462s 15ms/step - loss: 1.4856\n",
      "Epoch 10/10\n",
      "31368/31368 [==============================] - 459s 15ms/step - loss: 1.4833\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Model to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_new = preprocess([\"How are yo\"])\n",
    "#Y_pred = model.predict_classes(X_new)\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t the chosen to her than any man\n",
      "and so the other f\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"t\", temperature=0.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to co bard-ceacten robate\n",
      "and rang your sondures al\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpeniom,\n",
      "if you till have a bept ged hid ruck-faeer\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 7s 15ms/step - loss: 2.6244\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 2.2427\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 2.1131\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 2.0373\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.9870\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.9490\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.9205\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8985\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8815\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8641\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8512\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8396\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8300\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8199\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8126\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.8053\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7962\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7916\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7876\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7834\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7793\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7735\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7685\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7662\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7630\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7575\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7566\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7523\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7508\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7472\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7427\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7427\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7400\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7387\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7346\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7337\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7285\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7308\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7280\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7246\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7236\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7237\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7217\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7199\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7181\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7140\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7166\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7135\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7155\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.7110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
