{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcac3b7-e0b3-4575-b53b-ac772901cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf to txt file\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "def convert_pdf_to_txt(pdf_path, txt_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        total_pages = pdf_document.page_count\n",
    "\n",
    "        for page_num in range(total_pages):\n",
    "            page = pdf_document[page_num]\n",
    "            page_text = page.get_text()\n",
    "            text += page_text\n",
    "\n",
    "    # Remove extra numbers and spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', re.sub(r'\\d+', '', text.strip()))\n",
    "\n",
    "    # Save the cleaned text to a txt file\n",
    "    with open(txt_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "# Usage example\n",
    "pdf_path = 'arguments/145-orig_5426.pdf'\n",
    "txt_path = 'cleaned_text.txt'\n",
    "convert_pdf_to_txt(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409fd09d-55c8-4315-9c33-521f41b1a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences: 27\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "\n",
    "# def extract_text_between_markers(input_text):\n",
    "#     # Use a regular expression to capture all text between \"CHIEF JUSTICE ROBERTS:\" and the next occurrence of \"MR.\", \"MRS.\", \"MS.\", or \"JUSTICE\"\n",
    "#     pattern = re.compile(r'CHIEF JUSTICE ROBERTS:(.*?)(?:MR\\.|MRS\\.|MS\\.|JUSTICE\\b|$)')\n",
    "#     matches = pattern.finditer(input_text)\n",
    "#     count = 0\n",
    "#     text = \"\"\n",
    "\n",
    "#     for match in matches:\n",
    "#         # Extract the matched text\n",
    "#         extracted_text = match.group(1).strip()\n",
    "#         text += extracted_text\n",
    "#         count += 1\n",
    "\n",
    "#     return text, count\n",
    "\n",
    "# def main():\n",
    "#     # Read text from a file\n",
    "#     with open('cleaned_text.txt', 'r') as file:\n",
    "#         input_text = file.read()\n",
    "\n",
    "#     # Extract relevant text and count occurrences\n",
    "#     extracted_text, occurrences = extract_text_between_markers(input_text)\n",
    "\n",
    "#     # Save the extracted text to a new file\n",
    "#     with open('extracted_text.txt', 'w') as file:\n",
    "#         file.write(extracted_text)\n",
    "\n",
    "#     print(f\"Number of occurrences: {occurrences}\")\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c04a63-e7ef-4286-b84f-04baea25db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences: 27\n"
     ]
    }
   ],
   "source": [
    "# cleans text so we only have speach by chief justice roberts, with excess text from bottom removed\n",
    "import re\n",
    "\n",
    "def extract_text_between_markers(input_text):\n",
    "    # Use a regular expression to capture all text between \"CHIEF JUSTICE ROBERTS:\" and the next occurrence of \"MR.\", \"MRS.\", \"MS.\", or \"JUSTICE\"\n",
    "    pattern = re.compile(r'CHIEF JUSTICE ROBERTS:(.*?)(?:MR\\.|MRS\\.|MS\\.|JUSTICE\\b|$)')\n",
    "    matches = pattern.finditer(input_text)\n",
    "    count = 0\n",
    "    text = \"\"\n",
    "\n",
    "    for match in matches:\n",
    "        # Extract the matched text\n",
    "        extracted_text = match.group(1).strip()\n",
    "        text += extracted_text\n",
    "        count += 1\n",
    "\n",
    "    # Remove all text following the phrase \"Heritage Reporting Corporation Official $\"\n",
    "    end_marker = \"Heritage Reporting Corporation Official $\"\n",
    "    end_index = text.find(end_marker)\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    return text, count\n",
    "\n",
    "def main():\n",
    "    # Read text from a file\n",
    "    with open('cleaned_text.txt', 'r') as file:\n",
    "        input_text = file.read()\n",
    "\n",
    "    # Extract relevant text and count occurrences\n",
    "    extracted_text, occurrences = extract_text_between_markers(input_text)\n",
    "\n",
    "    # Save the extracted text to a new file\n",
    "    with open('extracted_text.txt', 'w') as file:\n",
    "        file.write(extracted_text)\n",
    "\n",
    "    print(f\"Number of occurrences: {occurrences}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d84b2-6252-48b3-b242-30201e2a5fb5",
   "metadata": {},
   "source": [
    "# all roberts pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3640d440-c57c-4bdb-b1be-386e691e72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "\n",
    "def convert_pdf_to_txt(pdf_path, txt_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        total_pages = pdf_document.page_count\n",
    "\n",
    "        for page_num in range(total_pages):\n",
    "            page = pdf_document[page_num]\n",
    "            page_text = page.get_text()\n",
    "            text += page_text\n",
    "\n",
    "    # Remove extra numbers and spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', re.sub(r'\\d+', '', text.strip()))\n",
    "\n",
    "    # Save the cleaned text to a txt file\n",
    "    with open(txt_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "def process_pdfs(input_folder, output_folder):\n",
    "    # Process all PDF files in the input folder\n",
    "    for pdf_file in os.listdir(input_folder):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(input_folder, pdf_file)\n",
    "\n",
    "            # Generate a unique name for the output text file\n",
    "            txt_filename = os.path.splitext(pdf_file)[0] + '_cleaned.txt'\n",
    "            txt_path = os.path.join(output_folder, txt_filename)\n",
    "\n",
    "            # Convert PDF to cleaned text file\n",
    "            convert_pdf_to_txt(pdf_path, txt_path)\n",
    "\n",
    "# Usage example\n",
    "input_folder = 'arguments/'\n",
    "output_folder = 'roberts_text/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "process_pdfs(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "928342e4-2146-4030-9382-ae759fdb47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 145-orig_5426_cleaned.txt, Number of occurrences: 27\n",
      "Processed: 156-orig_d18f_cleaned.txt, Number of occurrences: 45\n",
      "Processed: 20-1199_bi7a_cleaned.txt, Number of occurrences: 42\n",
      "Processed: 21-1043_j4pf_cleaned.txt, Number of occurrences: 23\n",
      "Processed: 21-1052_3145_cleaned.txt, Number of occurrences: 21\n",
      "Processed: 21-1086_1pd4_cleaned.txt, Number of occurrences: 32\n",
      "Processed: 21-1158_1bn2_cleaned.txt, Number of occurrences: 22\n",
      "Processed: 21-1164_7615_cleaned.txt, Number of occurrences: 21\n",
      "Processed: 21-1168_k6g1_cleaned.txt, Number of occurrences: 34\n",
      "Processed: 21-1170_565n_cleaned.txt, Number of occurrences: 16\n",
      "Processed: 21-1195_q8l1_cleaned.txt, Number of occurrences: 21\n",
      "Processed: 21-1239_iie0_cleaned.txt, Number of occurrences: 19\n",
      "Processed: 21-1270_82p9_cleaned.txt, Number of occurrences: 32\n",
      "Processed: 21-1271_2k81_cleaned.txt, Number of occurrences: 67\n",
      "Processed: 21-1326_i4e9_cleaned.txt, Number of occurrences: 25\n",
      "Processed: 21-1333_q4lp_cleaned.txt, Number of occurrences: 40\n",
      "Processed: 21-1397_8f57_cleaned.txt, Number of occurrences: 31\n",
      "Processed: 21-1436_7p84_cleaned.txt, Number of occurrences: 12\n",
      "Processed: 21-1449_11o5_cleaned.txt, Number of occurrences: 28\n",
      "Processed: 21-1450_258q_cleaned.txt, Number of occurrences: 26\n",
      "Processed: 21-1454_qm3j_cleaned.txt, Number of occurrences: 35\n",
      "Processed: 21-1484_7647_cleaned.txt, Number of occurrences: 34\n",
      "Processed: 21-1496_32q3_cleaned.txt, Number of occurrences: 43\n",
      "Processed: 21-1576_5i2q_cleaned.txt, Number of occurrences: 20\n",
      "Processed: 21-1599_f64i_cleaned.txt, Number of occurrences: 23\n",
      "Processed: 21-376_1p23_cleaned.txt, Number of occurrences: 81\n",
      "Processed: 21-432_p860_cleaned.txt, Number of occurrences: 14\n",
      "Processed: 21-442_ca7d_cleaned.txt, Number of occurrences: 13\n",
      "Processed: 21-454_m5n0_cleaned.txt, Number of occurrences: 40\n",
      "Processed: 21-468_f2ag_cleaned.txt, Number of occurrences: 42\n",
      "Processed: 21-476_k43e_cleaned.txt, Number of occurrences: 46\n",
      "Processed: 21-707_bb7j_cleaned.txt, Number of occurrences: 57\n",
      "Processed: 21-757_cjmb_cleaned.txt, Number of occurrences: 25\n",
      "Processed: 21-806_daeh_cleaned.txt, Number of occurrences: 40\n",
      "Processed: 21-846_geil_cleaned.txt, Number of occurrences: 10\n",
      "Processed: 21-857_iie0_cleaned.txt, Number of occurrences: 18\n",
      "Processed: 21-869_986b_cleaned.txt, Number of occurrences: 35\n",
      "Processed: 21-86_5g68_cleaned.txt, Number of occurrences: 27\n",
      "Processed: 21-887_b81g_cleaned.txt, Number of occurrences: 30\n",
      "Processed: 21-908_dc8e_cleaned.txt, Number of occurrences: 34\n",
      "Processed: 21-984_10n2_cleaned.txt, Number of occurrences: 23\n",
      "Processed: 22-105_i32c_cleaned.txt, Number of occurrences: 16\n",
      "Processed: 22-10_f3b7_cleaned.txt, Number of occurrences: 27\n",
      "Processed: 22-138_986b_cleaned.txt, Number of occurrences: 46\n",
      "Processed: 22-148_d523_cleaned.txt, Number of occurrences: 11\n",
      "Processed: 22-166_h4d8_cleaned.txt, Number of occurrences: 50\n",
      "Processed: 22-174_ancf_cleaned.txt, Number of occurrences: 25\n",
      "Processed: 22-179_jgkn_cleaned.txt, Number of occurrences: 20\n",
      "Processed: 22-196_8kj4_cleaned.txt, Number of occurrences: 24\n",
      "Processed: 22-200_5i29_cleaned.txt, Number of occurrences: 14\n",
      "Processed: 22-210_1edg_cleaned.txt, Number of occurrences: 12\n",
      "Processed: 22-227_94l8_cleaned.txt, Number of occurrences: 23\n",
      "Processed: 22-23_4m1d_cleaned.txt, Number of occurrences: 35\n",
      "Processed: 22-381_2135_cleaned.txt, Number of occurrences: 14\n",
      "Processed: 22-49_4f57_cleaned.txt, Number of occurrences: 17\n",
      "Processed: 22-506_k53l_cleaned.txt, Number of occurrences: 20\n",
      "Processed: 22-535_fdhk_cleaned.txt, Number of occurrences: 28\n",
      "Processed: 22-58_4fc4_cleaned.txt, Number of occurrences: 37\n",
      "Processed: 22-96_o2ka_cleaned.txt, Number of occurrences: 26\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def extract_text_between_markers(input_text):\n",
    "    # Use a regular expression to capture all text between \"CHIEF JUSTICE ROBERTS:\" and the next occurrence of \"MR.\", \"MRS.\", \"MS.\", or \"JUSTICE\"\n",
    "    pattern = re.compile(r'CHIEF JUSTICE ROBERTS:(.*?)(?:MR\\.|MRS\\.|MS\\.|JUSTICE\\b|$)')\n",
    "    matches = pattern.finditer(input_text)\n",
    "    count = 0\n",
    "    text = \"\"\n",
    "\n",
    "    for match in matches:\n",
    "        # Extract the matched text\n",
    "        extracted_text = match.group(1).strip()\n",
    "        text += extracted_text\n",
    "        count += 1\n",
    "\n",
    "    # Remove all text following the phrase \"Heritage Reporting Corporation Official $\"\n",
    "    end_marker = \"Heritage Reporting Corporation\"\n",
    "    end_index = text.find(end_marker)\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    return text, count\n",
    "\n",
    "def process_and_save_text(input_folder, output_folder):\n",
    "    # Process all text files in the input folder\n",
    "    for txt_file in os.listdir(input_folder):\n",
    "        if txt_file.lower().endswith('.txt'):\n",
    "            txt_path = os.path.join(input_folder, txt_file)\n",
    "\n",
    "            # Generate a unique name for the output text file\n",
    "            extracted_filename = os.path.splitext(txt_file)[0] + '_extracted.txt'\n",
    "            extracted_path = os.path.join(output_folder, extracted_filename)\n",
    "\n",
    "            # Read text from the file\n",
    "            with open(txt_path, 'r') as file:\n",
    "                input_text = file.read()\n",
    "\n",
    "            # Extract relevant text and count occurrences\n",
    "            extracted_text, occurrences = extract_text_between_markers(input_text)\n",
    "\n",
    "            # Save the extracted text to a new file\n",
    "            with open(extracted_path, 'w') as file:\n",
    "                file.write(extracted_text)\n",
    "\n",
    "            print(f\"Processed: {txt_file}, Number of occurrences: {occurrences}\")\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = 'text_files'\n",
    "output_folder = 'roberts'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process and save text from input_folder to output_folder\n",
    "process_and_save_text(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e514c7-6a22-48f1-9ff6-8541d971de6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
